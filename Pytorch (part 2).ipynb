{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Design Model (input, output size, forward pass)\n",
    "# 2) Construct loss and optimizer\n",
    "# 3) Training loop\n",
    "# -forward pass: compute prediction and loss\n",
    "# -backward pass: gradients\n",
    "# -update weights\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 0) prepare data\n",
    "X_numpy,y_numpy = datasets.make_regression(n_samples = 100, n_features = 1, noise = 20, random_state = 1)\n",
    "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
    "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
    "y = y.view(y.shape[0], 1)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "# 1) model\n",
    "input_size = n_features\n",
    "ouput_size = 1\n",
    "model = nn.Linear(input_size,ouput_size)\n",
    "\n",
    "# 2) loss and optimizer\n",
    "learning_rate = 0.01\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# 3) training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    # forward pass and loss\n",
    "    y_predicted = model(X)\n",
    "    loss = criterion(y_predicted, y)\n",
    "    \n",
    "    #backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    #update\n",
    "    optimizer.step()\n",
    "    \n",
    "    optimizer.zero_grad\n",
    "    \n",
    "    if (epoch+1)%10 == 0:\n",
    "        print(f'epoch {epoch+1}, loss = {loss.item():.4f}')\n",
    "        \n",
    "# plot\n",
    "predicted = model(X).detach().numpy()\n",
    "plt.plot(X_numpy, y_numpy, 'ro')\n",
    "plt.plot(X_numpy, predicted, 'b')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Design Model - input,output size, forward pass\n",
    "# 2) loss and optimizer\n",
    "# 3) backward pass\n",
    "# forward pass: compute prediction and loss\n",
    "# backward pass: gradients\n",
    "# update weights\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 0) data preparation\n",
    "bc = datasets.load_breast_cancer()\n",
    "X, y = bc.data, bc.target\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1234)\n",
    "\n",
    "#scale\n",
    "sc = StandardScaler()         #this will make our features to have zero mean and unit variance and always recommended to do\n",
    "                            #when we deal with logistic regression\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "y_train = y_train.view(y_train.shape[0], 1)\n",
    "y_test = y_test.view(y_test.shape[0], 1)\n",
    "\n",
    "\n",
    "# 1) model\n",
    "# f = wx + b, sigmoid\n",
    "class LogisticRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_input_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.Linear = nn.Linear(n_input_features, 1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        y_predicted = torch.sigmoid(self.Linear(x))          #sigmoid function will return a value betweeen 0 and 1\n",
    "        return y_predicted\n",
    "    \n",
    "model = LogisticRegression(n_features)\n",
    "\n",
    "\n",
    "# 2) loss and optimizer\n",
    "learning_rate = 0.01\n",
    "criterion = nn.BCELoss()                              #creates a criterion that measures the Binary Cross Entropy Loss\n",
    "                                        # between the target and the output\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# 3) training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    #forward pass and loss\n",
    "    y_predicted = model(X_train)\n",
    "    loss = criterion(y_predicted, y_train)\n",
    "    \n",
    "    #backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    #updates\n",
    "    optimizer.step()\n",
    "    \n",
    "    #zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if(epoch+1)%10 == 0:\n",
    "        print(f'epoch: {epoch+1}, loss= {loss.item():.4f}')\n",
    "        \n",
    "with torch.no_grad():\n",
    "    y_predicted = model(X_test)\n",
    "    y_predicted_cls = y_predicted.round()\n",
    "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
    "    print(f'accuracy = {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.7000,  0.0000,  1.9000,  0.0760, 11.0000, 34.0000,  0.9978,  3.5100,\n",
      "         0.5600,  9.4000,  5.0000,  0.0000]) tensor([7.4000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class WineDataset(Dataset):\n",
    "    \n",
    "    def __init__(self):\n",
    "        xy = np.loadtxt(\"C:\\\\Users\\\\User\\\\Desktop\\\\python\\\\WineQT.csv\",delimiter = ',', dtype = np.float32, skiprows = 1 )\n",
    "        self.x = torch.from_numpy(xy[:, 1:])\n",
    "        self.y = torch.from_numpy(xy[:, [0]])  #n_samples, 1\n",
    "        self.n_samples = xy.shape[0]\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        #dataset[0]\n",
    "        return self.x[index], self.y[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        #len(dataset)\n",
    "        return self.n_samples\n",
    "    \n",
    "dataset = WineDataset()\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([30, 75, 40, 58, 89, 50, 36, 14, 25, 56])\n",
      "1 tensor([ 2, 76, 53, 68, 61,  0, 80, 64, 67, 52])\n",
      "2 tensor([94, 60, 19, 99, 66,  8, 87, 23, 42, 91])\n",
      "3 tensor([70,  5, 77, 24, 73,  1, 49, 46, 63, 47])\n",
      "4 tensor([20, 95, 71, 39, 12, 55, 21,  6, 41, 28])\n",
      "5 tensor([74, 62,  7, 54, 13, 31, 93, 98, 81, 27])\n",
      "6 tensor([78,  9, 43,  4, 45, 32, 22, 92, 65, 88])\n",
      "7 tensor([72, 90, 29, 51, 69, 26, 44, 16,  3, 82])\n",
      "8 tensor([59, 86, 15, 48, 85, 57, 11, 38, 97, 79])\n",
      "9 tensor([83, 18, 10, 33, 37, 34, 17, 35, 96, 84])\n"
     ]
    }
   ],
   "source": [
    "# importing the required libraries\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# defining the Dataset class\n",
    "class data_set(Dataset):\n",
    "\tdef __init__(self):\n",
    "\t\tnumbers = list(range(0, 100, 1))\n",
    "\t\tself.data = numbers\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.data)\n",
    "\n",
    "\tdef __getitem__(self, index):\n",
    "\t\treturn self.data[index]\n",
    "\n",
    "\n",
    "dataset = data_set()\n",
    "\n",
    "# implementing dataloader on the dataset and printing per batch\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "for i, batch in enumerate(dataloader):\n",
    "\tprint(i, batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.7000e-01, 2.0000e-02, 1.3000e+00, 3.4000e-02, 1.8000e+01, 4.4000e+01,\n",
      "         9.9210e-01, 3.9000e+00, 6.2000e-01, 1.2800e+01, 6.0000e+00, 6.9500e+02],\n",
      "        [6.8000e-01, 2.0000e-02, 1.8000e+00, 8.7000e-02, 2.1000e+01, 9.4000e+01,\n",
      "         9.9440e-01, 3.5400e+00, 5.2000e-01, 1.0000e+01, 5.0000e+00, 1.4600e+02],\n",
      "        [6.1000e-01, 8.0000e-02, 2.1000e+00, 7.1000e-02, 1.6000e+01, 2.4000e+01,\n",
      "         9.9376e-01, 3.5600e+00, 7.7000e-01, 1.1100e+01, 6.0000e+00, 8.3100e+02],\n",
      "        [9.0000e-01, 3.4000e-01, 6.6000e+00, 1.1200e-01, 2.3000e+01, 9.9000e+01,\n",
      "         1.0029e+00, 3.2200e+00, 6.8000e-01, 9.3000e+00, 5.0000e+00, 8.8900e+02]]) tensor([[ 5.1000],\n",
      "        [ 5.8000],\n",
      "        [ 5.9000],\n",
      "        [10.7000]])\n",
      "1143 286\n",
      "epoch 1/2, step 5/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 10/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 15/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 20/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 25/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 30/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 35/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 40/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 45/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 50/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 55/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 60/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 65/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 70/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 75/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 80/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 85/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 90/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 95/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 100/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 105/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 110/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 115/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 120/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 125/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 130/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 135/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 140/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 145/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 150/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 155/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 160/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 165/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 170/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 175/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 180/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 185/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 190/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 195/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 200/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 205/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 210/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 215/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 220/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 225/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 230/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 235/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 240/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 245/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 250/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 255/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 260/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 265/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 270/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 275/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 280/286, inputs torch.Size([4, 12])\n",
      "epoch 1/2, step 285/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 5/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 10/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 15/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 20/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 25/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 30/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 35/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 40/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 45/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 50/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 55/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 60/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 65/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 70/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 75/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 80/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 85/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 90/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 95/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 100/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 105/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 110/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 115/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 120/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 125/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 130/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 135/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 140/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 145/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 150/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 155/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 160/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 165/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 170/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 175/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 180/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 185/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 190/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 195/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 200/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 205/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 210/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 215/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 220/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 225/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 230/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 235/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 240/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 245/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 250/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 255/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 260/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 265/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 270/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 275/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 280/286, inputs torch.Size([4, 12])\n",
      "epoch 2/2, step 285/286, inputs torch.Size([4, 12])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class WineDataset(Dataset):\n",
    "    \n",
    "    def __init__(self):\n",
    "        xy = np.loadtxt(\"C:\\\\Users\\\\User\\\\Desktop\\\\python\\\\WineQT.csv\",delimiter = ',', dtype = np.float32, skiprows = 1 )\n",
    "        self.x = torch.from_numpy(xy[:, 1:])\n",
    "        self.y = torch.from_numpy(xy[:, [0]])  #n_samples, 1\n",
    "        self.n_samples = xy.shape[0]\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        #dataset[0]\n",
    "        return self.x[index], self.y[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        #len(dataset)\n",
    "        return self.n_samples\n",
    "    \n",
    "dataset = WineDataset()\n",
    "dataloader = DataLoader(dataset = dataset, batch_size = 4, shuffle = True, num_workers = 0 )\n",
    "\n",
    "dataiter = iter(dataloader)\n",
    "data = dataiter.next()\n",
    "features, labels = data\n",
    "print(features, labels)\n",
    "\n",
    "#training loop \n",
    "num_epochs = 2\n",
    "total_samples = len(dataset)\n",
    "n_iterations = math.ceil(total_samples/4)\n",
    "print(total_samples, n_iterations)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs,labels) in enumerate(dataloader):\n",
    "        #forward backward, update\n",
    "        if (i+1) % 5 == 0:\n",
    "            print(f'epoch {epoch+1}/{num_epochs}, step {i+1}/{n_iterations}, inputs {inputs.shape}')\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected np.ndarray (got Tensor)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-cc4e70bcf860>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWineDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mToTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m \u001b[0mfirst_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfirst_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-cc4e70bcf860>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-cc4e70bcf860>\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, sample)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mMulTransform\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected np.ndarray (got Tensor)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class WineDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, transform = None):\n",
    "        xy = np.loadtxt(\"C:\\\\Users\\\\User\\\\Desktop\\\\python\\\\WineQT.csv\",delimiter = ',', dtype = np.float32, skiprows = 1 )\n",
    "        self.x = torch.from_numpy(xy[:, 1:])\n",
    "        self.y = torch.from_numpy(xy[:, [0]])  #n_samples, 1\n",
    "        self.n_samples = xy.shape[0]\n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        #dataset[0]\n",
    "        sample =  self.x[index], self.y[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        #len(dataset)\n",
    "        return self.n_samples\n",
    "    \n",
    "    \n",
    "class ToTensor:\n",
    "    def __call__(self,sample):\n",
    "        inputs, targets = sample\n",
    "        return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
    "    \n",
    "class MulTransform:\n",
    "    def __call__(self,factor):\n",
    "        self.factor = factor\n",
    "        \n",
    "    def __call__(self,sample):\n",
    "        inputs, target = sample\n",
    "        inputs *= sample\n",
    "        return inputs, target\n",
    "    \n",
    "dataset = WineDataset(transform = ToTensor())\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features)\n",
    "print(type(features), type(labels))\n",
    "\n",
    "composed = torchvision.transforms.compose([ToTensor(), MulTransform(2)])\n",
    "dataset = WineDataset(transform = composed)\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features)\n",
    "print(type(features), type(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without Transform\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[ 0.7     0.      1.9     0.076  11.     34.      0.9978  3.51    0.56\n",
      "  9.4     5.      0.    ] [7.4]\n",
      "\n",
      "With Tensor Transform\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "tensor([ 0.7000,  0.0000,  1.9000,  0.0760, 11.0000, 34.0000,  0.9978,  3.5100,\n",
      "         0.5600,  9.4000,  5.0000,  0.0000]) tensor([7.4000])\n",
      "\n",
      "With Tensor and Multiplication Transform\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "tensor([  2.8000,   0.0000,   7.6000,   0.3040,  44.0000, 136.0000,   3.9912,\n",
      "         14.0400,   2.2400,  37.6000,  20.0000,   0.0000]) tensor([7.4000])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Transforms can be applied to PIL images, tensors, ndarrays, or custom data\n",
    "during creation of the DataSet\n",
    "complete list of built-in transforms: \n",
    "https://pytorch.org/docs/stable/torchvision/transforms.html\n",
    "On Images\n",
    "---------\n",
    "CenterCrop, Grayscale, Pad, RandomAffine\n",
    "RandomCrop, RandomHorizontalFlip, RandomRotation\n",
    "Resize, Scale\n",
    "On Tensors\n",
    "----------\n",
    "LinearTransformation, Normalize, RandomErasing\n",
    "Conversion\n",
    "----------\n",
    "ToPILImage: from tensor or ndrarray\n",
    "ToTensor : from numpy.ndarray or PILImage\n",
    "Generic\n",
    "-------\n",
    "Use Lambda \n",
    "Custom\n",
    "------\n",
    "Write own class\n",
    "Compose multiple Transforms\n",
    "---------------------------\n",
    "composed = transforms.Compose([Rescale(256),\n",
    "                               RandomCrop(224)])\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class WineDataset(Dataset):\n",
    "\n",
    "    def __init__(self, transform=None):\n",
    "        xy = np.loadtxt('C:\\\\Users\\\\User\\\\Desktop\\\\python\\\\WineQT.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
    "        self.n_samples = xy.shape[0]\n",
    "\n",
    "        # note that we do not convert to tensor here\n",
    "        self.x_data = xy[:, 1:]\n",
    "        self.y_data = xy[:, [0]]\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.x_data[index], self.y_data[index]\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "# Custom Transforms\n",
    "# implement __call__(self, sample)\n",
    "class ToTensor:\n",
    "    # Convert ndarrays to Tensors\n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
    "\n",
    "class MulTransform:\n",
    "    # multiply inputs with a given factor\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        inputs *= self.factor\n",
    "        return inputs, targets\n",
    "\n",
    "print('Without Transform')\n",
    "dataset = WineDataset()\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(type(features), type(labels))\n",
    "print(features, labels)\n",
    "\n",
    "print('\\nWith Tensor Transform')\n",
    "dataset = WineDataset(transform=ToTensor())\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(type(features), type(labels))\n",
    "print(features, labels)\n",
    "\n",
    "print('\\nWith Tensor and Multiplication Transform')\n",
    "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(4)])\n",
    "dataset = WineDataset(transform=composed)\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(type(features), type(labels))\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax and Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax numpy: [0.65900114 0.24243297 0.09856589]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x)/np.sum(np.exp(x), axis = 0)\n",
    "\n",
    "x = np.array([2.0,1.0,0.1])\n",
    "outputs = softmax(x)\n",
    "print('Softmax numpy:',outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6590, 0.2424, 0.0986])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([2.0,1.0,0.1])\n",
    "outputs = torch.softmax(x, dim=0)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax numpy: [0.65900114 0.24243297 0.09856589]\n",
      "softmax torch: tensor([0.6590, 0.2424, 0.0986])\n",
      "Loss1 numpy: 0.3567\n",
      "Loss2 numpy: 2.3026\n",
      "PyTorch Loss1: 0.4170\n",
      "PyTorch Loss2: 1.8406\n",
      "Actual class: 0, Y_pred1: 0, Y_pred2: 1\n",
      "Batch Loss1:  0.2834\n",
      "Batch Loss2: 1.6418\n",
      "Actual class: tensor([2, 0, 1]), Y_pred1: tensor([2, 0, 1]), Y_pred2: tensor([0, 2, 0])\n"
     ]
    }
   ],
   "source": [
    "#a lot of time the softmax function is combined with the cross-entropy loss, this measures the performance of the classification model \n",
    "#whose output is the probability is between 0 and 1 and can be used in multi class problems and the loss increases if the predicted \n",
    "#probability diverges from the actual label\n",
    "#So the better our prediction the lower is the loss\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "#\n",
    "#        -> 2.0              -> 0.65  \n",
    "# Linear -> 1.0  -> Softmax  -> 0.25   -> CrossEntropy(y, y_hat)\n",
    "#        -> 0.1              -> 0.1                   \n",
    "#\n",
    "#     scores(logits)      probabilities\n",
    "#                           sum = 1.0\n",
    "#\n",
    "\n",
    "# Softmax applies the exponential function to each element, and normalizes\n",
    "# by dividing by the sum of all these exponentials\n",
    "# -> squashes the output to be between 0 and 1 = probability\n",
    "# sum of all probabilities is 1\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "x = np.array([2.0, 1.0, 0.1])\n",
    "outputs = softmax(x)\n",
    "print('softmax numpy:', outputs)\n",
    "\n",
    "x = torch.tensor([2.0, 1.0, 0.1])\n",
    "outputs = torch.softmax(x, dim=0) # along values along first axis\n",
    "print('softmax torch:', outputs)\n",
    "\n",
    "# Cross entropy\n",
    "# Cross-entropy loss, or log loss, measures the performance of a classification model \n",
    "# whose output is a probability value between 0 and 1. \n",
    "# -> loss increases as the predicted probability diverges from the actual label\n",
    "def cross_entropy(actual, predicted):\n",
    "    EPS = 1e-15\n",
    "    predicted = np.clip(predicted, EPS, 1 - EPS)\n",
    "    loss = -np.sum(actual * np.log(predicted))\n",
    "    return loss # / float(predicted.shape[0])\n",
    "\n",
    "# y must be one hot encoded\n",
    "# if class 0: [1 0 0]\n",
    "# if class 1: [0 1 0]\n",
    "# if class 2: [0 0 1]\n",
    "Y = np.array([1, 0, 0])\n",
    "Y_pred_good = np.array([0.7, 0.2, 0.1])\n",
    "Y_pred_bad = np.array([0.1, 0.3, 0.6])\n",
    "l1 = cross_entropy(Y, Y_pred_good)\n",
    "l2 = cross_entropy(Y, Y_pred_bad)\n",
    "print(f'Loss1 numpy: {l1:.4f}')\n",
    "print(f'Loss2 numpy: {l2:.4f}')\n",
    "\n",
    "# CrossEntropyLoss in PyTorch (applies Softmax)\n",
    "# nn.LogSoftmax + nn.NLLLoss\n",
    "# NLLLoss = negative log likelihood loss\n",
    "loss = nn.CrossEntropyLoss()\n",
    "# loss(input, target)\n",
    "\n",
    "# target is of size nSamples = 1\n",
    "# each element has class label: 0, 1, or 2\n",
    "# Y (=target) contains class labels, not one-hot\n",
    "Y = torch.tensor([0])\n",
    "\n",
    "# input is of size nSamples x nClasses = 1 x 3\n",
    "# y_pred (=input) must be raw, unnormalizes scores (logits) for each class, not softmax\n",
    "Y_pred_good = torch.tensor([[2.0, 1.0, 0.1]])\n",
    "Y_pred_bad = torch.tensor([[0.5, 2.0, 0.3]])\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)\n",
    "\n",
    "print(f'PyTorch Loss1: {l1.item():.4f}')\n",
    "print(f'PyTorch Loss2: {l2.item():.4f}')\n",
    "\n",
    "# get predictions\n",
    "_, predictions1 = torch.max(Y_pred_good, 1)\n",
    "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
    "print(f'Actual class: {Y.item()}, Y_pred1: {predictions1.item()}, Y_pred2: {predictions2.item()}')\n",
    "\n",
    "# allows batch loss for multiple samples\n",
    "\n",
    "# target is of size nBatch = 3\n",
    "# each element has class label: 0, 1, or 2\n",
    "Y = torch.tensor([2, 0, 1])\n",
    "\n",
    "# input is of size nBatch x nClasses = 3 x 3\n",
    "# Y_pred are logits (not softmax)\n",
    "Y_pred_good = torch.tensor(\n",
    "    [[0.1, 0.2, 3.9], # predict class 2\n",
    "    [1.2, 0.1, 0.3], # predict class 0\n",
    "    [0.3, 2.2, 0.2]]) # predict class 1\n",
    "\n",
    "Y_pred_bad = torch.tensor(\n",
    "    [[0.9, 0.2, 0.1],\n",
    "    [0.1, 0.3, 1.5],\n",
    "    [1.2, 0.2, 0.5]])\n",
    "\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)\n",
    "print(f'Batch Loss1:  {l1.item():.4f}')\n",
    "print(f'Batch Loss2: {l2.item():.4f}')\n",
    "\n",
    "# get predictions\n",
    "_, predictions1 = torch.max(Y_pred_good, 1)\n",
    "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
    "print(f'Actual class: {Y}, Y_pred1: {predictions1}, Y_pred2: {predictions2}')\n",
    "\n",
    "# Binary classification\n",
    "class NeuralNet1(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet1, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        # sigmoid at the end\n",
    "        y_pred = torch.sigmoid(out)\n",
    "        return y_pred\n",
    "\n",
    "model = NeuralNet1(input_size=28*28, hidden_size=5)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Multiclass problem\n",
    "class NeuralNet2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet2, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        # no softmax at the end\n",
    "        return out\n",
    "\n",
    "model = NeuralNet2(input_size=28*28, hidden_size=5, num_classes=3)\n",
    "criterion = nn.CrossEntropyLoss()  # (applies Softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
